{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8HeU2eB-uQ1"
      },
      "source": [
        "### Install and Upgrade Unsloth Library to Latest Nightly Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8lSNa9FYvmA7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCuyE0O6-82g"
      },
      "source": [
        "### Load and Configure a Pretrained FastLanguageModel with Custom Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "36dcf482487641dfbc0462372d5df200",
            "644a9739650b43d48ffbe950ece074f3",
            "101b0ff2dbd84d53b69798291340a4d1",
            "ee9a3d4ee2e34e319eda1b9b4d10c49e",
            "ebff33d290c24bf78ba41c6195227b83",
            "007d349d8b7842658f5f15377e3a501f",
            "8880c2f330be497abfc214adaca8ede9",
            "89db042077b5443e91c978587cc74b1e",
            "eea5debba9bf42c78247a4d6dc93bc03",
            "00700277731a4f64b1c99d81d8e07ada",
            "8623c2835aee46d08eead7c2b025ebfc",
            "f9c1f77c2cd64807a9465386548765bc",
            "dd5d9f2f667f4df7a1d58713ced72164",
            "4ed9de6d9e8b444894c5ebd87aefcf54",
            "6a8aca09ef624e87855cd3320152cc62",
            "9869435e408640e1a8ead714ac110c2c",
            "b10d9bc070254af1a9b381e790952cd6",
            "9d3d354965da4c36a88fc7f4578bdb88",
            "91ca8fcc1faf406e8c809872552e6b7c",
            "05668d441d7347c6aff6d4d34095b8f5",
            "7d45b8d9c9fb4fe9b31a91422aea05a3",
            "5bb8db0042b446d093d287e43232a7c6",
            "7a34c57912ac4b6c817773c4804b544e",
            "30d9126177b149758dcbdcf42809d881",
            "a573b5c1c672440391a8fe61fa1fe8da",
            "a28fd4c776494e5eb4eb85913e149e2b",
            "2040287ef7164618a25ae004028d1fdc",
            "87127a319f0b40e59918fb718edf28c5",
            "4f1fc66450d442c984a137f2037b0df6",
            "d227b74b2ec84a0ca966debd72860608",
            "6230dcdcd36a4e139c50aade200fb4b8",
            "ff86d22020714911a19c0bce7c965b25",
            "fc0ac78985ac4a978fb1cd639264faa4",
            "a1a881e7f2954be7a38e613d2ee32601",
            "02db2565a2dd4260b60ae74340c32d65",
            "0b2597ff13eb47acbfe4a55a876e9a34",
            "6d8694beaedf4452ab736f6af84f21de",
            "6cbd51600f4043dfb69bce2b7ff745b1",
            "9b5e30ccb8cd4eb4bb712bcefd6158af",
            "6e65b24b034d4eb0aaf0bced3a792fda",
            "6e67f33412214c968d0579886bfdeae1",
            "7aeba7d7c0574bbc8155fc337e12cb51",
            "c656ded7ba114460ae7bdcfa1e09d09f",
            "c0f72306b7ae4838886e3d3286ec2c23",
            "610f6177cfd44b70850543685efcb185",
            "c9dcec7f48774b96b235640d8ecffe80",
            "138ae713df654b9cb210c44645996b3e",
            "58aa77c2b6e54d38a40fd84dae016823",
            "eaee053bf01745cbbcc885ba88f4e5e4",
            "882985a6a26544c1bb63b52c9f7e7241",
            "c09acd7299734d369c9bd1136a13cb1d",
            "eef69f02928e4970a37c4e9eaeb29fdc",
            "cbbe182cccd5405a9dc611642b6691f6",
            "5656a2f25079495692cac526edbd5f1e",
            "bffc3facdc394fc6b1a8654279909597",
            "f212ca7310904947918097a71f40d0e1",
            "a1f92659fb70428db331302af3441000",
            "020e39d530554e3cb41e5e4e6243c823",
            "da27e391ff0346d682fe26e45d0433e3",
            "7991d1feed4742598e81147ab7a017c6",
            "e0bb4bea7c774b54a45e0cd6f3278f62",
            "e62100e7f631432884539a2020787bc3",
            "ae498964e94f42acb7c67395dfbe5edd",
            "3fe161f53570417ba7efd357ca06e7dd",
            "f5bf26f820394df2879d72bfd046c883",
            "ce694697bbe947fa89a3cadeaabb2d37"
          ]
        },
        "id": "2eSvM9zX_2d3",
        "outputId": "7d2e80b3-9018-4272-cb1f-c3d19c8be82d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.1.8: Fast Gemma patching. Transformers: 4.47.1.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36dcf482487641dfbc0462372d5df200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.07G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9c1f77c2cd64807a9465386548765bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a34c57912ac4b6c817773c4804b544e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/40.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1a881e7f2954be7a38e613d2ee32601",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "610f6177cfd44b70850543685efcb185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f212ca7310904947918097a71f40d0e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import the FastLanguageModel module from the unsloth library\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# Define the maximum sequence length for the model (can be customized)\n",
        "max_seq_length = 4096  # Choose any! RoPE Scaling is auto-supported internally.\n",
        "\n",
        "# Specify the data type for the model (None for auto-detection, or specify Float16/Bfloat16)\n",
        "dtype = None  # Float16 for Tesla T4, V100; Bfloat16 for Ampere+; None for auto-detection.\n",
        "\n",
        "# Enable or disable 4-bit quantization to reduce memory usage\n",
        "load_in_4bit = True  # Use 4-bit quantization. Set to False if not required.\n",
        "\n",
        "# Load the pretrained model and tokenizer with the specified parameters\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/gemma-2b-bnb-4bit\",  # Model name to be loaded\n",
        "    max_seq_length=max_seq_length,             # Maximum sequence length\n",
        "    dtype=dtype,                               # Data type\n",
        "    load_in_4bit=load_in_4bit                  # Enable 4-bit quantization\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H6EWbe-t_bk"
      },
      "source": [
        "### We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "55e7c7b4-e481-4928-8d72-bc6e84d2b268"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.1.8 patched 18 layers with 18 QKV layers, 18 O layers and 18 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkCQUItbC-lU"
      },
      "source": [
        "#### Formatting Medical Reasoning Dataset for ORPOTrainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GetrTh37qgDp"
      },
      "outputs": [],
      "source": [
        "# Formatting Medical Reasoning Dataset for ORPOTrainer\n",
        "# This script formats the dataset by creating prompts based on the given instruction, input, and responses.\n",
        "# The format follows the Alpaca prompt style, including \"instruction\", \"input\", and \"response\" sections.\n",
        "\n",
        "# Define the Alpaca-style prompt template for formatting the data\n",
        "alpaca_prompt = \"\"\"Below is a medical scenario with an input that describes a situation or a question related to healthcare. Write a response that appropriately completes the medical reasoning request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "# Define the End of Sequence (EOS) token\n",
        "EOS_TOKEN = \"<EOS>\"  # Placeholder for EOS token, ensure this matches your tokenizer's EOS token\n",
        "\n",
        "def format_prompt(sample):\n",
        "    # Extract the instruction, input, accepted response, and rejected response from the sample\n",
        "    instruction = sample[\"instruction\"]  # Instruction on how to approach the medical problem\n",
        "    input_data = sample[\"Input\"]\n",
        "    accepted = sample[\"accepted\"]  # The accepted (valid) reasoning response\n",
        "    rejected = sample[\"rejected\"]  # The rejected (invalid) reasoning response\n",
        "\n",
        "    # ORPOTrainer expects keys: prompt (formatted instruction and input), chosen (accepted response), and rejected (rejected response)\n",
        "    # Create a formatted prompt using the Alpaca template, leaving the response section empty\n",
        "    sample[\"Input\"] = alpaca_prompt.format(instruction, input_data, \"\")\n",
        "\n",
        "    # Add the accepted response, appending the EOS token at the end\n",
        "    sample[\"chosen\"] = accepted + EOS_TOKEN\n",
        "\n",
        "    # Add the rejected response, appending the EOS token at the end\n",
        "    sample[\"rejected\"] = rejected + EOS_TOKEN\n",
        "\n",
        "    return sample  # Return the formatted sample for further use\n",
        "\n",
        "# Placeholder statement, does nothing, but ensures syntactical correctness\n",
        "pass\n",
        "\n",
        "# Example of loading and processing the dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"SURESHBEEKHANI/medical-reasoning-orpo\"\n",
        "dataset = load_dataset(dataset_name, split=\"all\")\n",
        "dataset = dataset.shuffle(seed=42).select(range(4200))  # Limit to 1000 samples for a quick demo\n",
        "\n",
        "# Apply the `format_prompt` function to each sample in the dataset to format them correctly\n",
        "dataset = dataset.map(format_prompt)  # The `map` function applies `format_prompt` across all samples in the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PH-7Cudu8Ja"
      },
      "source": [
        "Let's print out some examples to see how the dataset should look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1738BWgZ2ij",
        "outputId": "4cd0d20f-f292-4a74-db2f-6e7cc6ea5913"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Input', 'accepted', 'rejected', 'instruction', 'chosen'],\n",
              "    num_rows: 4200\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF63zQqNlNJC",
        "outputId": "ce76792b-63f5-4acb-d409-a854acd31408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INSTRUCTION: ==================================================\n",
            "('Below is a medical scenario with an input that describes a situation or a '\n",
            " 'question related to healthcare. Write a response that appropriately '\n",
            " 'completes the medical reasoning request.\\n'\n",
            " '\\n'\n",
            " '### Instruction:\\n'\n",
            " 'Given the following medical question or situation, provide the most suitable '\n",
            " 'reasoning or explanation.\\n'\n",
            " '\\n'\n",
            " '### Input:\\n'\n",
            " 'A 58-year-old woman presents with a swelling in her right vulva accompanied '\n",
            " 'by pain during walking and coitus. On pelvic examination, a mildly tender, '\n",
            " 'fluctuant mass is found just outside the introitus in the right vulva, near '\n",
            " \"the Bartholin's gland. Given her age and symptoms, what is the definitive \"\n",
            " 'treatment for this condition?\\n'\n",
            " '\\n'\n",
            " '### Response:\\n')\n",
            "ACCEPTED: ==================================================\n",
            "(\"Okay, so there's a 58-year-old woman who's having this painful swelling \"\n",
            " \"around her right vulva. She says it's painful when she walks or during sex. \"\n",
            " \"That's got to be really uncomfortable. Let's see what we know from the exam. \"\n",
            " \"There's this tender bump near her Bartholin's gland. Hmm, a fluctuant mass \"\n",
            " 'like that often means something like a cyst or maybe an abscess.\\n'\n",
            " '\\n'\n",
            " \"Now, age is definitely an important factor here. She's 58, so we're a bit \"\n",
            " 'more concerned about things we might not worry as much about in younger '\n",
            " 'women. Over 40, you always need a little radar ping for anything that could '\n",
            " 'be malignant in the vulvar area. Yep, definitely better safe than sorry.\\n'\n",
            " '\\n'\n",
            " \"So let's think through treatment options. If we were dealing with a younger \"\n",
            " 'woman, especially under 40, maybe we could just try some simple drainage '\n",
            " \"techniques or even sitz baths. But with her, let's not risk being too \"\n",
            " 'conservative. Ah, and a word like marsupialization pops into my mind for '\n",
            " 'cysts, but her age shifts our strategy.\\n'\n",
            " '\\n'\n",
            " \"For a woman of her age, we're looking at approaching this more definitively. \"\n",
            " 'Right, surgery would both handle the swelling and give us a clear picture '\n",
            " 'through histology and rule out something more sinister like cancer. Oh, '\n",
            " 'definitely need to cover all bases.\\n'\n",
            " '\\n'\n",
            " \"So, it all adds up to removing the Bartholin's gland completely. It \"\n",
            " 'addresses the symptoms and lets us check everything out under the '\n",
            " 'microscope. That feels like a strong, safe choice in this case. Yeah, '\n",
            " \"surgical excision, that's the ticket. Makes sense, right? In the case of a \"\n",
            " '58-year-old woman presenting with a painful, fluctuant swelling near the '\n",
            " \"Bartholin's gland, the definitive treatment approach is surgical excision of \"\n",
            " 'the gland. This approach is particularly important due to her age, as the '\n",
            " 'risk of malignancy in vulvar lesions increases in women over 40. By removing '\n",
            " 'the gland surgically, we can address the symptoms and also perform a '\n",
            " 'histological examination to rule out any malignant processes. This ensures '\n",
            " 'both effective treatment and thorough evaluation of any underlying '\n",
            " 'pathology.<EOS>')\n",
            "REJECTED: ==================================================\n",
            "'Treatment: Drainage of the mass.<EOS>'\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "row = dataset[1]\n",
        "print('INSTRUCTION: ' + '=' * 50)\n",
        "pprint.pprint(row[\"Input\"])\n",
        "print('ACCEPTED: ' + '=' * 50)\n",
        "pprint.pprint(row[\"chosen\"])\n",
        "print('REJECTED: ' + '=' * 50)\n",
        "pprint.pprint(row[\"rejected\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oqyleKojqgDq"
      },
      "outputs": [],
      "source": [
        "# Enable reward modelling stats\n",
        "# Import the PatchDPOTrainer class from the unsloth module\n",
        "from unsloth import PatchDPOTrainer\n",
        "\n",
        "# Instantiate PatchDPOTrainer to enable reward modelling statistics\n",
        "PatchDPOTrainer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ZlnJpkxIuV"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `ORPOTrainer`! More docs here: [TRL ORPO docs](https://huggingface.co/docs/trl/main/en/orpo_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "17f0ed3f984549189d96fda6c4fcb974",
            "df6d1c5d8b624e65a1ba6fb370b4a3d1",
            "d9063cfbec0d4b7180f13d9bd434f737",
            "04801bcbee20430ca103b1c4a5e44a9e",
            "79ed6acbe87e435f9a6f1c5494c45560",
            "7cf95ec94ded417a8bc4ba0ecc751be5",
            "8eb9cd54b4dc4692b24b6452fb63de86",
            "23bb83d49ba34934a78b4eb049bcea42",
            "ea14f712e6d245899503692207100265",
            "eb2c00a64dd14935a27df2030314667b",
            "5b80944363af4b2da56bc0b0158d16de",
            "d4982b2c04a04c5d92b0a6bcfc7ff267",
            "05a09f1ae0f2433ca932f643f2f4cc49",
            "b7bc6c978ccb4991901b31a580111bf7",
            "fe5b7f91f3fa484da54c12faf6d51ae1",
            "b4b351df09444e7e924da1586cebe2a6",
            "0314d24d16bf46918ea73d472573c7dd",
            "80f2df7010a44bc994845dcda306d916",
            "6878ce769cb2483d857fbe24100f6416",
            "8a531745d9d2474ca3ddc73cb274bc0d",
            "6376f6c22b6443eea076ea33a27e21b1",
            "8e6a1e0e3c324018bc83dd12942865a7"
          ]
        },
        "id": "QtoqUw80QDV0",
        "outputId": "64282969-2b5a-4e83-ddbb-e5d944e17efe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17f0ed3f984549189d96fda6c4fcb974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4982b2c04a04c5d92b0a6bcfc7ff267",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import ORPOConfig, ORPOTrainer  # Importing necessary classes from trl\n",
        "from unsloth import is_bfloat16_supported  # Importing function to check for bfloat16 support\n",
        "\n",
        "orpo_trainer = ORPOTrainer(  # Initializing ORPOTrainer instance\n",
        "    model=model,  # Assigning the model object\n",
        "    train_dataset=dataset,  # Assigning the training dataset\n",
        "    tokenizer=tokenizer,  # Assigning the tokenizer object\n",
        "    args=ORPOConfig(  # Initializing ORPOConfig with training arguments\n",
        "        max_length=max_seq_length,  # Setting maximum sequence length\n",
        "        max_prompt_length=max_seq_length // 2,  # Setting maximum prompt length\n",
        "        max_completion_length=max_seq_length // 2,  # Setting maximum completion length\n",
        "        per_device_train_batch_size=1,  # Batch size per device for training\n",
        "        gradient_accumulation_steps=4,  # Number of gradient accumulation steps\n",
        "        beta=0.1,  # Beta parameter for ORPO\n",
        "        logging_steps=1,  # Logging frequency during training\n",
        "        optim=\"adamw_8bit\",  # Optimizer type (8-bit adamw)\n",
        "        lr_scheduler_type=\"linear\",  # Learning rate scheduler type\n",
        "        max_steps=30,  # Maximum training steps (for quick demo, change for full training)\n",
        "        fp16=not is_bfloat16_supported(),  # Whether to use FP16 (float16) if not bfloat16 supported\n",
        "        bf16=is_bfloat16_supported(),  # Whether to use BF16 (bfloat16) if supported\n",
        "        output_dir=\"outputs\",  # Output directory for model checkpoints and logs\n",
        "        report_to=\"none\",  # Reporting destination (none for no reporting)\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EWGFqAo5Q2me",
        "outputId": "28118ad4-b614-4fc0-ab31-5d50e7a4cddc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 4,200 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 4 | Total steps = 30\n",
            " \"-____-\"     Number of trainable parameters = 19,611,648\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 02:37, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>rewards / chosen</th>\n",
              "      <th>rewards / rejected</th>\n",
              "      <th>rewards / accuracies</th>\n",
              "      <th>rewards / margins</th>\n",
              "      <th>logps / rejected</th>\n",
              "      <th>logps / chosen</th>\n",
              "      <th>logits / rejected</th>\n",
              "      <th>logits / chosen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.076900</td>\n",
              "      <td>-0.307604</td>\n",
              "      <td>-0.962221</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.654617</td>\n",
              "      <td>-9.622208</td>\n",
              "      <td>-3.076042</td>\n",
              "      <td>-136.423187</td>\n",
              "      <td>-24.874859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.793400</td>\n",
              "      <td>-0.278727</td>\n",
              "      <td>-0.971243</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.692517</td>\n",
              "      <td>-9.712435</td>\n",
              "      <td>-2.787268</td>\n",
              "      <td>-128.502686</td>\n",
              "      <td>-24.926565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.220800</td>\n",
              "      <td>-0.321204</td>\n",
              "      <td>-0.692108</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.370904</td>\n",
              "      <td>-6.921082</td>\n",
              "      <td>-3.212042</td>\n",
              "      <td>-130.866257</td>\n",
              "      <td>-25.897560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.205000</td>\n",
              "      <td>-0.320140</td>\n",
              "      <td>-1.153894</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833754</td>\n",
              "      <td>-11.538943</td>\n",
              "      <td>-3.201405</td>\n",
              "      <td>-118.451355</td>\n",
              "      <td>-25.475842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.980400</td>\n",
              "      <td>-0.297967</td>\n",
              "      <td>-0.904319</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.606353</td>\n",
              "      <td>-9.043194</td>\n",
              "      <td>-2.979667</td>\n",
              "      <td>-129.034119</td>\n",
              "      <td>-25.772474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.869700</td>\n",
              "      <td>-0.274342</td>\n",
              "      <td>-0.422061</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.147719</td>\n",
              "      <td>-4.220611</td>\n",
              "      <td>-2.743423</td>\n",
              "      <td>-80.072800</td>\n",
              "      <td>-59.113464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.123600</td>\n",
              "      <td>-0.312088</td>\n",
              "      <td>-1.215499</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.903411</td>\n",
              "      <td>-12.154988</td>\n",
              "      <td>-3.120877</td>\n",
              "      <td>-124.870918</td>\n",
              "      <td>-25.650391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.634400</td>\n",
              "      <td>-0.252910</td>\n",
              "      <td>-0.286387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.033477</td>\n",
              "      <td>-2.863869</td>\n",
              "      <td>-2.529102</td>\n",
              "      <td>-82.132278</td>\n",
              "      <td>-43.489361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.431200</td>\n",
              "      <td>-0.336199</td>\n",
              "      <td>-1.046396</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.710196</td>\n",
              "      <td>-10.463959</td>\n",
              "      <td>-3.361993</td>\n",
              "      <td>-95.447136</td>\n",
              "      <td>-39.933029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.969700</td>\n",
              "      <td>-0.296968</td>\n",
              "      <td>-1.159624</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862656</td>\n",
              "      <td>-11.596243</td>\n",
              "      <td>-2.969681</td>\n",
              "      <td>-120.981216</td>\n",
              "      <td>-25.623039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.876300</td>\n",
              "      <td>-0.279240</td>\n",
              "      <td>-0.336466</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.057226</td>\n",
              "      <td>-3.364661</td>\n",
              "      <td>-2.792397</td>\n",
              "      <td>-101.773949</td>\n",
              "      <td>-43.625198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>3.058900</td>\n",
              "      <td>-0.304825</td>\n",
              "      <td>-0.873745</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.568920</td>\n",
              "      <td>-8.737446</td>\n",
              "      <td>-3.048248</td>\n",
              "      <td>-132.738419</td>\n",
              "      <td>-25.038235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>3.034900</td>\n",
              "      <td>-0.302977</td>\n",
              "      <td>-1.328479</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.025502</td>\n",
              "      <td>-13.284794</td>\n",
              "      <td>-3.029774</td>\n",
              "      <td>-115.345482</td>\n",
              "      <td>-25.281666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3.220600</td>\n",
              "      <td>-0.321934</td>\n",
              "      <td>-1.077998</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.756065</td>\n",
              "      <td>-10.779984</td>\n",
              "      <td>-3.219335</td>\n",
              "      <td>-115.497421</td>\n",
              "      <td>-26.517162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>3.166900</td>\n",
              "      <td>-0.316651</td>\n",
              "      <td>-1.154448</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.837796</td>\n",
              "      <td>-11.544477</td>\n",
              "      <td>-3.166514</td>\n",
              "      <td>-116.788437</td>\n",
              "      <td>-25.801678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3.060900</td>\n",
              "      <td>-0.302688</td>\n",
              "      <td>-0.827833</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.525145</td>\n",
              "      <td>-8.278330</td>\n",
              "      <td>-3.026884</td>\n",
              "      <td>-97.563446</td>\n",
              "      <td>-47.204105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>3.176600</td>\n",
              "      <td>-0.310075</td>\n",
              "      <td>-0.875518</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.565443</td>\n",
              "      <td>-8.755178</td>\n",
              "      <td>-3.100751</td>\n",
              "      <td>-93.835434</td>\n",
              "      <td>-49.718254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.990700</td>\n",
              "      <td>-0.293568</td>\n",
              "      <td>-0.712413</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.418845</td>\n",
              "      <td>-7.124132</td>\n",
              "      <td>-2.935682</td>\n",
              "      <td>-94.715500</td>\n",
              "      <td>-56.254410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>3.016300</td>\n",
              "      <td>-0.293840</td>\n",
              "      <td>-0.566818</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.272978</td>\n",
              "      <td>-5.668179</td>\n",
              "      <td>-2.938401</td>\n",
              "      <td>-110.781021</td>\n",
              "      <td>-52.246624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.802100</td>\n",
              "      <td>-0.276587</td>\n",
              "      <td>-0.697486</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.420899</td>\n",
              "      <td>-6.974861</td>\n",
              "      <td>-2.765869</td>\n",
              "      <td>-118.861053</td>\n",
              "      <td>-25.965130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>2.796600</td>\n",
              "      <td>-0.278338</td>\n",
              "      <td>-0.817235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538897</td>\n",
              "      <td>-8.172348</td>\n",
              "      <td>-2.783382</td>\n",
              "      <td>-120.400650</td>\n",
              "      <td>-25.901695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>3.079500</td>\n",
              "      <td>-0.302484</td>\n",
              "      <td>-0.870801</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.568317</td>\n",
              "      <td>-8.708010</td>\n",
              "      <td>-3.024844</td>\n",
              "      <td>-92.851151</td>\n",
              "      <td>-49.259304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>2.695100</td>\n",
              "      <td>-0.269406</td>\n",
              "      <td>-0.932172</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.662766</td>\n",
              "      <td>-9.321716</td>\n",
              "      <td>-2.694059</td>\n",
              "      <td>-126.848267</td>\n",
              "      <td>-24.490005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>3.173900</td>\n",
              "      <td>-0.315297</td>\n",
              "      <td>-0.689398</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.374101</td>\n",
              "      <td>-6.893983</td>\n",
              "      <td>-3.152975</td>\n",
              "      <td>-133.483398</td>\n",
              "      <td>-25.380577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.075200</td>\n",
              "      <td>-0.305527</td>\n",
              "      <td>-0.629994</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.324467</td>\n",
              "      <td>-6.299937</td>\n",
              "      <td>-3.055265</td>\n",
              "      <td>-142.283417</td>\n",
              "      <td>-25.705584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>3.108400</td>\n",
              "      <td>-0.310197</td>\n",
              "      <td>-0.830823</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.520626</td>\n",
              "      <td>-8.308228</td>\n",
              "      <td>-3.101972</td>\n",
              "      <td>-139.415268</td>\n",
              "      <td>-24.924179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>3.027400</td>\n",
              "      <td>-0.296548</td>\n",
              "      <td>-0.472746</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.176198</td>\n",
              "      <td>-4.727459</td>\n",
              "      <td>-2.965479</td>\n",
              "      <td>-111.186798</td>\n",
              "      <td>-42.748680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>3.019700</td>\n",
              "      <td>-0.301173</td>\n",
              "      <td>-0.770543</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.469370</td>\n",
              "      <td>-7.705426</td>\n",
              "      <td>-3.011728</td>\n",
              "      <td>-137.868652</td>\n",
              "      <td>-26.439333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>2.994100</td>\n",
              "      <td>-0.298427</td>\n",
              "      <td>-0.983569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.685143</td>\n",
              "      <td>-9.835692</td>\n",
              "      <td>-2.984266</td>\n",
              "      <td>-128.065643</td>\n",
              "      <td>-25.894142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.849100</td>\n",
              "      <td>-0.278801</td>\n",
              "      <td>-0.377611</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.098809</td>\n",
              "      <td>-3.776107</td>\n",
              "      <td>-2.788014</td>\n",
              "      <td>-126.707344</td>\n",
              "      <td>-26.234207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=3.017614761988322, metrics={'train_runtime': 161.6462, 'train_samples_per_second': 0.742, 'train_steps_per_second': 0.186, 'total_flos': 0.0, 'train_loss': 3.017614761988322, 'epoch': 0.02857142857142857})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orpo_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgEvCW76xblp"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DJPbbtGxcFJ",
        "outputId": "7458713f-a057-47ee-e087-61e8ba6e66d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<bos>Below is a medical scenario with an input that describes a situation or a question related to healthcare. Write a response that appropriately completes the medical reasoning request.\\n\\n### Instruction:\\nGiven the following medical question or situation, provide the most suitable reasoning or explanation\\n\\n### Input:\\nA Fabry-Perot interferometer is used to resolve the mode structure of a He-Ne laser operating at 6328 Ã… with a frequency separation between the modes of 150 MHz. Determine the required plate spacing for cases where the reflectance of the mirrors is (a) 0.9 and (b) 0.999.\\n\\n### Response:\\n**a) 0.9**\\n\\nThe required plate spacing for a Fabry-Perot interferometer is given by the formula:\\n\\n$$d = \\\\frac{\\\\lambda}{4n}$$\\n\\nwhere:\\n\\n* d is the plate spacing\\n* Î» is the wavelength of light\\n* n is the refractive index of the medium between the mirrors\\n\\nFor (a) 0.9, n = 1.33, and:\\n\\n$$d = \\\\frac{6328 \\\\times 10^{-8}}{4(1.33)} = 0.019 \\\\text{ mm}$$\\n\\n**b) 0.999**\\n\\nThe required plate spacing for a Fabry-Perot interferometer is given by the formula:\\n\\n$$d = \\\\frac{\\\\lambda}{4n}$$\\n\\nwhere:\\n\\n* d is the plate spacing\\n* Î» is the wavelength of light\\n* n is the refractive index of the medium']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "# This is a placeholder for the prompt template, presumably copied from another section of the code.\n",
        "\n",
        "# Enable native 2x faster inference using FastLanguageModel\n",
        "# This allows the model to run inference faster by optimizing internal processes for speed.\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Prepare input data by formatting the prompt with specific instructions and input/output placeholders\n",
        "inputs = tokenizer(\n",
        "    [\n",
        "        # Format the prompt with the given instruction, input, and an empty output for generation\n",
        "        alpaca_prompt.format(\n",
        "            \"Given the following medical question or situation, provide the most suitable reasoning or explanation\",  # Instruction text to guide the model\n",
        "            \"A Fabry-Perot interferometer is used to resolve the mode structure of a He-Ne laser operating at 6328 Ã… with a frequency separation between the modes of 150 MHz. Determine the required plate spacing for cases where the reflectance of the mirrors is (a) 0.9 and (b) 0.999.\",  # The input query/question\n",
        "            \"\",  # Empty output to leave space for the generated response\n",
        "        )\n",
        "    ],\n",
        "    # Return tokenized inputs in PyTorch tensor format\n",
        "    return_tensors = \"pt\"\n",
        ").to(\"cuda\")  # Move inputs to GPU for faster computation\n",
        "\n",
        "# Generate output based on the model's inference from the formatted input\n",
        "outputs = model.generate(\n",
        "    **inputs,              # Pass the tokenized inputs to the model\n",
        "    max_new_tokens = 200,  # Limit the output to a maximum of 200 tokens\n",
        "    use_cache = True       # Enable caching to speed up the generation process by reusing previous computations\n",
        ")\n",
        "\n",
        "# Decode the generated tokens back into text format for human-readable output\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "absTV8M1xzwz"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKzWRN1Px0Bg",
        "outputId": "e7b1aca8-4c3d-4db8-a733-e97b1ec618b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos>Below is a medical scenario with an input that describes a situation or a question related to healthcare. Write a response that appropriately completes the medical reasoning request.\n",
            "\n",
            "### Instruction:\n",
            "Given the following medical question or situation, provide the most suitable reasoning or explanation\n",
            "\n",
            "### Input:\n",
            "A Fabry-Perot interferometer is used to resolve the mode structure of a He-Ne laser operating at 6328 Ã… with a frequency separation between the modes of 150 MHz. Determine the required plate spacing for cases where the reflectance of the mirrors is (a) 0.9 and (b) 0.999.\n",
            "\n",
            "### Response:\n",
            "**a) 0.9**\n",
            "\n",
            "The required plate spacing for a Fabry-Perot interferometer is given by the formula:\n",
            "\n",
            "$$d = \\frac{\\lambda}{4n}$$\n",
            "\n",
            "where:\n",
            "\n",
            "* d is the plate spacing\n",
            "* Î» is the wavelength of light\n",
            "* n is the refractive index of the medium between the mirrors\n",
            "\n",
            "For (a) 0.9, n = 1.33, and:\n",
            "\n",
            "$$d = \\frac{6328 \\times 10^{-8}}{4(1.33)} = 0.019 \\text{ mm}$$\n",
            "\n",
            "**b) 0.999**\n",
            "\n",
            "The required plate spacing for a Fabry-Perot interferometer is given by the formula:\n",
            "\n",
            "$$d = \\frac{\\lambda}{4n}$$\n",
            "\n",
            "where:\n",
            "\n",
            "* d is the plate spacing\n",
            "* Î» is the wavelength of light\n",
            "* n is the refractive index of the medium between the mirrors\n",
            "\n",
            "For (b) 0.999, n = 1.36, and:\n",
            "\n",
            "$$d = \\frac{6328 \\times 10^{-8}}{4(1.36)} = 0.004 \\text{ mm}$$<eos>\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "# This is a placeholder for the prompt template, which is presumably defined elsewhere in the code.\n",
        "\n",
        "# Enable native 2x faster inference by optimizing the model for inference tasks\n",
        "# This method configures the model to use efficient inference settings, improving the processing speed.\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Prepare the input data for the model by formatting the prompt with a specific instruction and input\n",
        "inputs = tokenizer(\n",
        "    [\n",
        "        # Format the prompt by inserting the instruction, input question, and leave the output blank for generation\n",
        "        alpaca_prompt.format(\n",
        "            \"Given the following medical question or situation, provide the most suitable reasoning or explanation\",  # Instruction provided to the model\n",
        "            \"A Fabry-Perot interferometer is used to resolve the mode structure of a He-Ne laser operating at 6328 Ã… with a frequency separation between the modes of 150 MHz. Determine the required plate spacing for cases where the reflectance of the mirrors is (a) 0.9 and (b) 0.999.\",  # Input question or scenario\n",
        "            \"\",  # Blank output, as the model will generate the response\n",
        "        )\n",
        "    ],\n",
        "    return_tensors = \"pt\"  # Ensure the input is tokenized and returned as a PyTorch tensor\n",
        ").to(\"cuda\")  # Move the tensor to the GPU for faster processing\n",
        "\n",
        "# Import the TextStreamer class from the transformers library\n",
        "# The TextStreamer is used to stream the output during generation, allowing more efficient generation of long text outputs.\n",
        "from transformers import TextStreamer\n",
        "\n",
        "# Initialize the TextStreamer with the tokenizer to handle token-to-text conversion during generation\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "\n",
        "# Generate text from the model based on the provided inputs\n",
        "# Using the TextStreamer, this will stream the generation process, allowing tokens to be decoded and displayed progressively\n",
        "_ = model.generate(\n",
        "    **inputs,                 # Pass the tokenized input data to the model\n",
        "    streamer = text_streamer, # Use the TextStreamer to handle the output streaming\n",
        "    max_new_tokens = 1000      # Limit the generation to a maximum of 128 new tokens\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_3rdZXmx3Hh"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJbRqLynx3a8",
        "outputId": "bf5a6037-aa4d-4f56-aa70-7e7f5366ec3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.model',\n",
              " 'lora_model/added_tokens.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwIRb8DByBGg"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPHJs9wDyBbN",
        "outputId": "ee95f2ae-4481-4dd0-8a5b-da9dc2508355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.1.8: Fast Gemma patching. Transformers: 4.47.1.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<bos>Below is a medical scenario with an input that describes a situation or a question related to healthcare. Write a response that appropriately completes the medical reasoning request.\\n\\n### Instruction:\\nGiven the following medical question or situation, provide the most suitable reasoning or explanation\\n\\n### Input:\\nA Fabry-Perot interferometer is used to resolve the mode structure of a He-Ne laser operating at 6328 Ã… with a frequency separation between the modes of 150 MHz. Determine the required plate spacing for cases where the reflectance of the mirrors is (a) 0.9 and (b) 0.999.\\n\\n### Response:\\n**a) 0.9**\\n\\nThe required plate spacing for a Fabry-Perot interferometer is given by the formula:\\n\\n$$d = \\\\frac{\\\\lambda}{4n}$$\\n\\nwhere:\\n\\n* d is the plate spacing\\n* Î» is the wavelength of light\\n* n is the refractive']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import FastLanguageModel from the unsloth library, which provides methods for fast inference with language models\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Load the pre-trained model and tokenizer using the specified configuration\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"lora_model\",  # Specify the model name or path to the model you trained or want to use\n",
        "    max_seq_length = max_seq_length,  # Set the maximum sequence length for tokenized inputs\n",
        "    dtype = dtype,  # Define the data type for the model (e.g., float32, float16, etc.)\n",
        "    load_in_4bit = load_in_4bit,  # If True, load the model with reduced precision (4-bit) for more efficient memory usage\n",
        ")\n",
        "\n",
        "# Enable native 2x faster inference by configuring the model for optimized inference operations\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# alpaca_prompt = You MUST copy from above!\n",
        "# The alpaca_prompt should be defined elsewhere in the code or copied from previous sections.\n",
        "\n",
        "# Prepare the input data by formatting the prompt with a specific instruction and input for the model\n",
        "inputs = tokenizer(\n",
        "    [\n",
        "        # Format the prompt string by injecting the instruction, input scenario, and an empty output for the model to generate\n",
        "        alpaca_prompt.format(\n",
        "            \"Given the following medical question or situation, provide the most suitable reasoning or explanation\",  # Instruction text to guide the model\n",
        "            \"A Fabry-Perot interferometer is used to resolve the mode structure of a He-Ne laser operating at 6328 Ã… with a frequency separation between the modes of 150 MHz. Determine the required plate spacing for cases where the reflectance of the mirrors is (a) 0.9 and (b) 0.999.\",  # Input question or scientific scenario\n",
        "            \"\",  # Blank output, as the model will generate the response in place of this empty string\n",
        "        )\n",
        "    ],\n",
        "    return_tensors = \"pt\"  # Ensure the tokenized input is returned as a PyTorch tensor\n",
        ").to(\"cuda\")  # Move the tokenized input to the GPU for faster processing during inference\n",
        "\n",
        "# Generate output from the model based on the tokenized input\n",
        "outputs = model.generate(\n",
        "    **inputs,           # Pass the tokenized inputs to the model\n",
        "    max_new_tokens = 64,  # Set the maximum number of new tokens to be generated in the output\n",
        "    use_cache = True     # Use the model's caching mechanism to speed up subsequent generations by reusing computations\n",
        ")\n",
        "\n",
        "# Decode the generated output tokens back into human-readable text format\n",
        "tokenizer.batch_decode(outputs)  # Decode the generated tokens into a string and return the result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssjW3ST2yI1L"
      },
      "source": [
        "### Push the trained model to the Hugging Face Model Hub using the GGUF format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2c9c7fb62e944c6daad7d77555dd73fc",
            "61045119a1be499da497eca727457205",
            "f8b30af0a46248a282d1fb4a215ff4fe",
            "8758cf23949e457d879d16acc58e5f55",
            "7fb069b7acd7497caf4c29068bcb6dbb",
            "dbfbfcabe9fe4e5dad74c8798312552f",
            "f45a55fe04ab48c390a83504b92d3830",
            "20c080b3f9484b49bf328b61fb7cc860",
            "7cb901bce8664f8dabaeacc52d3bb1c3",
            "fe92c00f2ed6449da1af94a30514b71f",
            "d4805764b6fc4fbd9949b4ca4fe9c451",
            "58971006c2ca4d5e83357f8dc70c11f9",
            "a0612875a1dc4c858d240bdb19d4c2a7",
            "aef99fc38f17468289f3a1175a01d4fc",
            "a1951547b51a486e8e574363d93ed12b",
            "e0061933e2864df8b2b3f43a8e461258",
            "f524c709a6814c5f845b206964a38588",
            "d7d1c64a0d7f44d9bc4f31b9c92ca5cd",
            "bb90d2e5869c4162979674adc57a068b",
            "a611a94cda3b4f9a97bfc496e618bf9b",
            "5e5ade2662904e7b8c581d2cdc4b906e",
            "ee74f515bb9f418eb0dfd3448c01b95e",
            "a4eb53e328c441088ea2a9a6c8a9d8cd",
            "0a8942b119324312af97d4fd73b29b93",
            "813acd4406a647f99bdabdd3a99ae8f7",
            "f9310d3691a645778a74bb12ace3a55b",
            "04b3451b87cf4b038803b3f41ff1b0cd",
            "c919c1b5db824b78bf23c1b233511d43",
            "61635bfde06247608f86bf26308ee3b9",
            "d76f57c399cc48338fb95cacea292f93",
            "e7098cbb996a4fe5905bd0a3b500073e",
            "8fdad3bfd3a942a48a17b5ed34370325",
            "d679d7942f4448ea8e32941acd39a152",
            "df17d60cc7374c1488d2d33460326c27",
            "23233d21b94046419cb129a22fd4affd",
            "c04f45cb9ce24d42827e126a8767a17f",
            "b10b5137b3294d51a89de1e494aa156e",
            "496c0e9f5a404704a9920693b41e92e8",
            "f3e3e647f48349f985a1a6af3229623d",
            "e055c0fdc5fc4666a0e48aa5f0bbcfda",
            "e3bf3bafaa234315b3313e4de4c5f192",
            "8b8295182e8049e29b0431a314ea4bdc",
            "221a9b339aaa4c0da99c85851b88d1f2",
            "0476063cc726418fa7be30d8e9d9db2e",
            "bb67d619a0304d47925fb8bc7a9c39bd",
            "ac25224af7284b1abe2e7e19f0de393c",
            "3aad570f9bf24029b1c771e4c3ea3a61",
            "17a2250aa60b43b3924b2c42e536409d",
            "163dfc72f01848e895dc07c1bc6a832a",
            "5a126cfba190437d821142251035ef75",
            "90b45001e9f148dc8fc507a19c380c39",
            "74609d62cc87424091aef609e0b8f365",
            "25dc782ccf8847d7936720bbca9baa12",
            "66f29807805d4deba2be97392bb23e9d",
            "d7b97bee444347038f8e755f5fe2d39f",
            "df3e1d0be28c405e85d2379f02991226",
            "3d24792983064082b3258f8d7561a714",
            "08ca2f99eb37478c9383aada2b9c4e31",
            "c6bfb0916d244358a59ac2bc7d9adc19",
            "a56795ce4f5a4204b165b3fa468a202c",
            "acae8f5e411d4a3f8f723b342f928d65",
            "abbfab7e68df4703a328c4b38997e784",
            "2e2355800c4345568e90931a15f771db",
            "e1550bc28bf84cb7bb9395c450cb63cb",
            "c482ffad2ca34238aa2650b31a794c1c",
            "6f7b3f094e7742b6a3ed35d36c528d70"
          ]
        },
        "id": "FKVTNAwyyKFR",
        "outputId": "389126a5-d5eb-4e4b-cfa6-33dc7fefe157"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### Your chat template has a BOS token. We shall remove it temporarily.\n",
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 2.1G\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 4.84 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 10.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/pytorch_model-00001-of-00002.bin...\n",
            "Unsloth: Saving SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/pytorch_model-00002-of-00002.bin...\n",
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting gemma model. Can use fast conversion = False.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0', 'q5_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning into f16 GGUF format.\n",
            "The output location will be /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> F16, shape = {2048, 256000}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> F16, shape = {2048, 256}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 16384}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> F16, shape = {16384, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 2\n",
            "INFO:gguf.vocab:Setting special token type eos to 1\n",
            "INFO:gguf.vocab:Setting special token type unk to 3\n",
            "INFO:gguf.vocab:Setting special token type pad to 0\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n",
            "' + message['content'] | trim + '<end_of_turn>\n",
            "' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n",
            "'}}{% endif %}\n",
            "WARNING:gguf.vocab:No handler for special token type prefix with id 67 - skipping\n",
            "WARNING:gguf.vocab:No handler for special token type suffix with id 69 - skipping\n",
            "WARNING:gguf.vocab:No handler for special token type middle with id 68 - skipping\n",
            "WARNING:gguf.vocab:No handler for special token type fsep with id 70 - skipping\n",
            "INFO:gguf.vocab:Setting special token type eot to 107\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf: n_tensors = 164, total_size = 5.0G\n",
            "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.01G/5.01G [01:21<00:00, 61.3Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 4621 (6eecde3c)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf' to '/content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 32 key-value pairs and 164 tensors from /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gemma 2b It Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = it-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = gemma\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
            "llama_model_loader: - kv   7:                       gemma.context_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                     gemma.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   9:                          gemma.block_count u32              = 18\n",
            "llama_model_loader: - kv  10:                  gemma.feed_forward_length u32              = 16384\n",
            "llama_model_loader: - kv  11:                 gemma.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv  12:              gemma.attention.head_count_kv u32              = 1\n",
            "llama_model_loader: - kv  13:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  14:                 gemma.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv  15:               gemma.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  16:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  24:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  27:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  29:                tokenizer.ggml.eot_token_id u32              = 107\n",
            "llama_model_loader: - kv  30:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   37 tensors\n",
            "llama_model_loader: - type  f16:  127 tensors\n",
            "[   1/ 164]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   2/ 164]                    token_embd.weight - [ 2048, 256000,     1,     1], type =    f16, converting to q6_K .. size =  1000.00 MiB ->   410.16 MiB\n",
            "[   3/ 164]                  blk.0.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[   4/ 164]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   5/ 164]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   6/ 164]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   7/ 164]                  blk.0.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[   8/ 164]                blk.0.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[   9/ 164]                blk.0.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  10/ 164]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  11/ 164]                  blk.0.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  12/ 164]                  blk.1.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  13/ 164]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  14/ 164]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  15/ 164]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  16/ 164]                  blk.1.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  17/ 164]                blk.1.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  18/ 164]                blk.1.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  19/ 164]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  20/ 164]                  blk.1.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  21/ 164]                  blk.2.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  22/ 164]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  23/ 164]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  24/ 164]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  25/ 164]                  blk.2.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  26/ 164]                blk.2.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  27/ 164]                blk.2.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  28/ 164]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  29/ 164]                  blk.2.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  30/ 164]                  blk.3.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  31/ 164]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  32/ 164]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  33/ 164]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  34/ 164]                  blk.3.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  35/ 164]                blk.3.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  36/ 164]                blk.3.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  37/ 164]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  38/ 164]                  blk.3.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  39/ 164]                  blk.4.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  40/ 164]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  41/ 164]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  42/ 164]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  43/ 164]                  blk.4.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  44/ 164]                blk.4.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  45/ 164]                blk.4.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  46/ 164]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  47/ 164]                  blk.4.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  48/ 164]                  blk.5.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  49/ 164]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  50/ 164]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  51/ 164]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  52/ 164]                  blk.5.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  53/ 164]                blk.5.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  54/ 164]                blk.5.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  55/ 164]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  56/ 164]                  blk.5.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  57/ 164]                  blk.6.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  58/ 164]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  59/ 164]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  60/ 164]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  61/ 164]                  blk.6.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  62/ 164]                blk.6.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  63/ 164]                blk.6.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  64/ 164]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  65/ 164]                  blk.6.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  66/ 164]                  blk.7.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  67/ 164]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  68/ 164]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  69/ 164]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  70/ 164]                  blk.7.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  71/ 164]                blk.7.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  72/ 164]                blk.7.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  73/ 164]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  74/ 164]                  blk.7.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  75/ 164]                  blk.8.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  76/ 164]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  77/ 164]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  78/ 164]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  79/ 164]                  blk.8.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  80/ 164]                blk.8.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  81/ 164]                blk.8.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  82/ 164]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  83/ 164]                  blk.8.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  84/ 164]                  blk.9.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  85/ 164]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  86/ 164]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  87/ 164]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  88/ 164]                  blk.9.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  89/ 164]                blk.9.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  90/ 164]                blk.9.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  91/ 164]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  92/ 164]                  blk.9.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[  93/ 164]                 blk.10.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[  94/ 164]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  95/ 164]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  96/ 164]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  97/ 164]                 blk.10.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  98/ 164]               blk.10.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  99/ 164]               blk.10.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 100/ 164]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 101/ 164]                 blk.10.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 102/ 164]                 blk.11.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 103/ 164]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 104/ 164]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 105/ 164]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 106/ 164]                 blk.11.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 107/ 164]               blk.11.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 108/ 164]               blk.11.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 109/ 164]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 110/ 164]                 blk.11.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 111/ 164]                 blk.12.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 112/ 164]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 113/ 164]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 114/ 164]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 115/ 164]                 blk.12.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 116/ 164]               blk.12.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 117/ 164]               blk.12.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 118/ 164]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 119/ 164]                 blk.12.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 120/ 164]                 blk.13.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 121/ 164]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 122/ 164]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 123/ 164]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 124/ 164]                 blk.13.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 125/ 164]               blk.13.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 126/ 164]               blk.13.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 127/ 164]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 128/ 164]                 blk.13.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 129/ 164]                 blk.14.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 130/ 164]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 131/ 164]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 132/ 164]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 133/ 164]                 blk.14.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 134/ 164]               blk.14.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 135/ 164]               blk.14.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 136/ 164]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 137/ 164]                 blk.14.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 138/ 164]                 blk.15.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 139/ 164]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 140/ 164]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 141/ 164]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 142/ 164]                 blk.15.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 143/ 164]               blk.15.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 144/ 164]               blk.15.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 145/ 164]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 146/ 164]                 blk.15.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 147/ 164]                 blk.16.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 148/ 164]              blk.16.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 149/ 164]            blk.16.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 150/ 164]                 blk.16.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 151/ 164]                 blk.16.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 152/ 164]               blk.16.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 153/ 164]               blk.16.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 154/ 164]               blk.16.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 155/ 164]                 blk.16.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 156/ 164]                 blk.17.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q4_K .. size =     1.00 MiB ->     0.28 MiB\n",
            "[ 157/ 164]              blk.17.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 158/ 164]            blk.17.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 159/ 164]                 blk.17.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 160/ 164]                 blk.17.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 161/ 164]               blk.17.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 162/ 164]               blk.17.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "[ 163/ 164]               blk.17.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 164/ 164]                 blk.17.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q4_K .. size =    64.00 MiB ->    18.00 MiB\n",
            "llama_model_quantize_impl: model size  =  4780.29 MB\n",
            "llama_model_quantize_impl: quant size  =  1548.98 MB\n",
            "\n",
            "main: quantize time = 251674.72 ms\n",
            "main:    total time = 251674.72 ms\n",
            "Unsloth: Conversion completed! Output location: /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.Q4_K_M.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q8_0. This might take 20 minutes...\n",
            "main: build = 4621 (6eecde3c)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf' to '/content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.Q8_0.gguf' as Q8_0 using 4 threads\n",
            "llama_model_loader: loaded meta data with 32 key-value pairs and 164 tensors from /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gemma 2b It Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = it-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = gemma\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
            "llama_model_loader: - kv   7:                       gemma.context_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                     gemma.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   9:                          gemma.block_count u32              = 18\n",
            "llama_model_loader: - kv  10:                  gemma.feed_forward_length u32              = 16384\n",
            "llama_model_loader: - kv  11:                 gemma.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv  12:              gemma.attention.head_count_kv u32              = 1\n",
            "llama_model_loader: - kv  13:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  14:                 gemma.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv  15:               gemma.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  16:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  24:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  27:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  29:                tokenizer.ggml.eot_token_id u32              = 107\n",
            "llama_model_loader: - kv  30:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   37 tensors\n",
            "llama_model_loader: - type  f16:  127 tensors\n",
            "[   1/ 164]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   2/ 164]                    token_embd.weight - [ 2048, 256000,     1,     1], type =    f16, converting to q8_0 .. size =  1000.00 MiB ->   531.25 MiB\n",
            "[   3/ 164]                  blk.0.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[   4/ 164]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   5/ 164]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[   6/ 164]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[   7/ 164]                  blk.0.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[   8/ 164]                blk.0.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[   9/ 164]                blk.0.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  10/ 164]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  11/ 164]                  blk.0.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  12/ 164]                  blk.1.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  13/ 164]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  14/ 164]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  15/ 164]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  16/ 164]                  blk.1.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  17/ 164]                blk.1.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  18/ 164]                blk.1.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  19/ 164]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  20/ 164]                  blk.1.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  21/ 164]                  blk.2.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  22/ 164]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  23/ 164]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  24/ 164]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  25/ 164]                  blk.2.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  26/ 164]                blk.2.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  27/ 164]                blk.2.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  28/ 164]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  29/ 164]                  blk.2.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  30/ 164]                  blk.3.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  31/ 164]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  32/ 164]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  33/ 164]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  34/ 164]                  blk.3.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  35/ 164]                blk.3.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  36/ 164]                blk.3.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  37/ 164]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  38/ 164]                  blk.3.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  39/ 164]                  blk.4.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  40/ 164]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  41/ 164]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  42/ 164]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  43/ 164]                  blk.4.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  44/ 164]                blk.4.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  45/ 164]                blk.4.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  46/ 164]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  47/ 164]                  blk.4.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  48/ 164]                  blk.5.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  49/ 164]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  50/ 164]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  51/ 164]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  52/ 164]                  blk.5.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  53/ 164]                blk.5.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  54/ 164]                blk.5.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  55/ 164]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  56/ 164]                  blk.5.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  57/ 164]                  blk.6.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  58/ 164]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  59/ 164]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  60/ 164]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  61/ 164]                  blk.6.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  62/ 164]                blk.6.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  63/ 164]                blk.6.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  64/ 164]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  65/ 164]                  blk.6.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  66/ 164]                  blk.7.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  67/ 164]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  68/ 164]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  69/ 164]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  70/ 164]                  blk.7.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  71/ 164]                blk.7.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  72/ 164]                blk.7.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  73/ 164]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  74/ 164]                  blk.7.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  75/ 164]                  blk.8.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  76/ 164]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  77/ 164]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  78/ 164]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  79/ 164]                  blk.8.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  80/ 164]                blk.8.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  81/ 164]                blk.8.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  82/ 164]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  83/ 164]                  blk.8.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  84/ 164]                  blk.9.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  85/ 164]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  86/ 164]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  87/ 164]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  88/ 164]                  blk.9.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  89/ 164]                blk.9.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  90/ 164]                blk.9.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  91/ 164]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  92/ 164]                  blk.9.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  93/ 164]                 blk.10.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  94/ 164]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  95/ 164]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  96/ 164]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  97/ 164]                 blk.10.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[  98/ 164]               blk.10.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[  99/ 164]               blk.10.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 100/ 164]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 101/ 164]                 blk.10.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 102/ 164]                 blk.11.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 103/ 164]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 104/ 164]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 105/ 164]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 106/ 164]                 blk.11.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 107/ 164]               blk.11.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 108/ 164]               blk.11.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 109/ 164]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 110/ 164]                 blk.11.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 111/ 164]                 blk.12.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 112/ 164]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 113/ 164]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 114/ 164]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 115/ 164]                 blk.12.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 116/ 164]               blk.12.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 117/ 164]               blk.12.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 118/ 164]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 119/ 164]                 blk.12.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 120/ 164]                 blk.13.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 121/ 164]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 122/ 164]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 123/ 164]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 124/ 164]                 blk.13.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 125/ 164]               blk.13.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 126/ 164]               blk.13.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 127/ 164]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 128/ 164]                 blk.13.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 129/ 164]                 blk.14.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 130/ 164]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 131/ 164]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 132/ 164]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 133/ 164]                 blk.14.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 134/ 164]               blk.14.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 135/ 164]               blk.14.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 136/ 164]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 137/ 164]                 blk.14.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 138/ 164]                 blk.15.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 139/ 164]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 140/ 164]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 141/ 164]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 142/ 164]                 blk.15.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 143/ 164]               blk.15.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 144/ 164]               blk.15.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 145/ 164]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 146/ 164]                 blk.15.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 147/ 164]                 blk.16.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 148/ 164]              blk.16.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 149/ 164]            blk.16.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 150/ 164]                 blk.16.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 151/ 164]                 blk.16.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 152/ 164]               blk.16.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 153/ 164]               blk.16.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 154/ 164]               blk.16.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 155/ 164]                 blk.16.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 156/ 164]                 blk.17.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 157/ 164]              blk.17.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 158/ 164]            blk.17.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 159/ 164]                 blk.17.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 160/ 164]                 blk.17.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q8_0 .. size =     1.00 MiB ->     0.53 MiB\n",
            "[ 161/ 164]               blk.17.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 162/ 164]               blk.17.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "[ 163/ 164]               blk.17.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 164/ 164]                 blk.17.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q8_0 .. size =    64.00 MiB ->    34.00 MiB\n",
            "llama_model_quantize_impl: model size  =  4780.29 MB\n",
            "llama_model_quantize_impl: quant size  =  2539.66 MB\n",
            "\n",
            "main: quantize time = 85789.61 ms\n",
            "main:    total time = 85789.61 ms\n",
            "Unsloth: Conversion completed! Output location: /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.Q8_0.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This might take 20 minutes...\n",
            "main: build = 4621 (6eecde3c)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf' to '/content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.Q5_K_M.gguf' as Q5_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 32 key-value pairs and 164 tensors from /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gemma 2b It Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = it-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = gemma\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
            "llama_model_loader: - kv   7:                       gemma.context_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                     gemma.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   9:                          gemma.block_count u32              = 18\n",
            "llama_model_loader: - kv  10:                  gemma.feed_forward_length u32              = 16384\n",
            "llama_model_loader: - kv  11:                 gemma.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv  12:              gemma.attention.head_count_kv u32              = 1\n",
            "llama_model_loader: - kv  13:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  14:                 gemma.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv  15:               gemma.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  16:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  24:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  27:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  29:                tokenizer.ggml.eot_token_id u32              = 107\n",
            "llama_model_loader: - kv  30:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   37 tensors\n",
            "llama_model_loader: - type  f16:  127 tensors\n",
            "[   1/ 164]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   2/ 164]                    token_embd.weight - [ 2048, 256000,     1,     1], type =    f16, converting to q6_K .. size =  1000.00 MiB ->   410.16 MiB\n",
            "[   3/ 164]                  blk.0.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[   4/ 164]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   5/ 164]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[   6/ 164]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[   7/ 164]                  blk.0.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[   8/ 164]                blk.0.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[   9/ 164]                blk.0.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  10/ 164]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  11/ 164]                  blk.0.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  12/ 164]                  blk.1.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  13/ 164]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  14/ 164]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  15/ 164]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  16/ 164]                  blk.1.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  17/ 164]                blk.1.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  18/ 164]                blk.1.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  19/ 164]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  20/ 164]                  blk.1.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  21/ 164]                  blk.2.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  22/ 164]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  23/ 164]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  24/ 164]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  25/ 164]                  blk.2.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  26/ 164]                blk.2.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  27/ 164]                blk.2.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  28/ 164]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  29/ 164]                  blk.2.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  30/ 164]                  blk.3.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  31/ 164]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  32/ 164]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  33/ 164]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  34/ 164]                  blk.3.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  35/ 164]                blk.3.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  36/ 164]                blk.3.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  37/ 164]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  38/ 164]                  blk.3.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  39/ 164]                  blk.4.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  40/ 164]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  41/ 164]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  42/ 164]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  43/ 164]                  blk.4.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  44/ 164]                blk.4.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  45/ 164]                blk.4.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  46/ 164]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  47/ 164]                  blk.4.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  48/ 164]                  blk.5.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  49/ 164]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  50/ 164]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  51/ 164]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  52/ 164]                  blk.5.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  53/ 164]                blk.5.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  54/ 164]                blk.5.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  55/ 164]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  56/ 164]                  blk.5.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  57/ 164]                  blk.6.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  58/ 164]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  59/ 164]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  60/ 164]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  61/ 164]                  blk.6.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  62/ 164]                blk.6.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  63/ 164]                blk.6.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  64/ 164]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  65/ 164]                  blk.6.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  66/ 164]                  blk.7.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  67/ 164]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  68/ 164]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  69/ 164]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  70/ 164]                  blk.7.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  71/ 164]                blk.7.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  72/ 164]                blk.7.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  73/ 164]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  74/ 164]                  blk.7.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  75/ 164]                  blk.8.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  76/ 164]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  77/ 164]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  78/ 164]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  79/ 164]                  blk.8.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  80/ 164]                blk.8.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  81/ 164]                blk.8.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  82/ 164]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  83/ 164]                  blk.8.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  84/ 164]                  blk.9.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  85/ 164]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  86/ 164]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  87/ 164]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  88/ 164]                  blk.9.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  89/ 164]                blk.9.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  90/ 164]                blk.9.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  91/ 164]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  92/ 164]                  blk.9.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[  93/ 164]                 blk.10.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[  94/ 164]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  95/ 164]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  96/ 164]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  97/ 164]                 blk.10.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[  98/ 164]               blk.10.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[  99/ 164]               blk.10.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 100/ 164]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 101/ 164]                 blk.10.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 102/ 164]                 blk.11.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 103/ 164]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 104/ 164]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 105/ 164]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 106/ 164]                 blk.11.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 107/ 164]               blk.11.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 108/ 164]               blk.11.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 109/ 164]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 110/ 164]                 blk.11.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 111/ 164]                 blk.12.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 112/ 164]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 113/ 164]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 114/ 164]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 115/ 164]                 blk.12.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 116/ 164]               blk.12.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 117/ 164]               blk.12.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 118/ 164]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 119/ 164]                 blk.12.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 120/ 164]                 blk.13.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 121/ 164]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 122/ 164]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 123/ 164]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 124/ 164]                 blk.13.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 125/ 164]               blk.13.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 126/ 164]               blk.13.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 127/ 164]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 128/ 164]                 blk.13.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 129/ 164]                 blk.14.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 130/ 164]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 131/ 164]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 132/ 164]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 133/ 164]                 blk.14.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 134/ 164]               blk.14.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 135/ 164]               blk.14.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 136/ 164]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 137/ 164]                 blk.14.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 138/ 164]                 blk.15.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 139/ 164]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 140/ 164]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 141/ 164]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 142/ 164]                 blk.15.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 143/ 164]               blk.15.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 144/ 164]               blk.15.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 145/ 164]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 146/ 164]                 blk.15.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 147/ 164]                 blk.16.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 148/ 164]              blk.16.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 149/ 164]            blk.16.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 150/ 164]                 blk.16.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 151/ 164]                 blk.16.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 152/ 164]               blk.16.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 153/ 164]               blk.16.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 154/ 164]               blk.16.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 155/ 164]                 blk.16.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 156/ 164]                 blk.17.attn_k.weight - [ 2048,   256,     1,     1], type =    f16, converting to q5_K .. size =     1.00 MiB ->     0.34 MiB\n",
            "[ 157/ 164]              blk.17.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 158/ 164]            blk.17.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 159/ 164]                 blk.17.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 160/ 164]                 blk.17.attn_v.weight - [ 2048,   256,     1,     1], type =    f16, converting to q6_K .. size =     1.00 MiB ->     0.41 MiB\n",
            "[ 161/ 164]               blk.17.ffn_down.weight - [16384,  2048,     1,     1], type =    f16, converting to q6_K .. size =    64.00 MiB ->    26.25 MiB\n",
            "[ 162/ 164]               blk.17.ffn_gate.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "[ 163/ 164]               blk.17.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 164/ 164]                 blk.17.ffn_up.weight - [ 2048, 16384,     1,     1], type =    f16, converting to q5_K .. size =    64.00 MiB ->    22.00 MiB\n",
            "llama_model_quantize_impl: model size  =  4780.29 MB\n",
            "llama_model_quantize_impl: quant size  =  1748.67 MB\n",
            "\n",
            "main: quantize time = 219127.81 ms\n",
            "main:    total time = 219127.81 ms\n",
            "Unsloth: Conversion completed! Output location: /content/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning/unsloth.Q5_K_M.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c9c7fb62e944c6daad7d77555dd73fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58971006c2ca4d5e83357f8dc70c11f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved GGUF to https://huggingface.co/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4eb53e328c441088ea2a9a6c8a9d8cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df17d60cc7374c1488d2d33460326c27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unsloth.Q8_0.gguf:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved GGUF to https://huggingface.co/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb67d619a0304d47925fb8bc7a9c39bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df3e1d0be28c405e85d2379f02991226",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unsloth.Q5_K_M.gguf:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### We removed it in GGUF's chat template for you.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved GGUF to https://huggingface.co/SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning\n"
          ]
        }
      ],
      "source": [
        "# Push the trained model to the Hugging Face Model Hub using the GGUF format\n",
        "model.push_to_hub_gguf(\n",
        "    \"SURESHBEEKHANI/Gemma_2B_Medical_ORPO_RLHF_Fine_Tuning\",  # Specify the model repository path on Hugging Face Hub. Replace \"hf\" with your Hugging Face username.\n",
        "    tokenizer,  # Pass the tokenizer associated with the model to ensure compatibility on the hub\n",
        "    quantization_method=[\"q4_k_m\", \"q8_0\", \"q5_k_m\"],  # Specify the quantization methods to apply for optimized model storage (e.g., q4_k_m, q8_0, q5_k_m)\n",
        "    token=\"\",  # Provide the Hugging Face token for authentication. Obtain a token at https://huggingface.co/settings/tokens\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00700277731a4f64b1c99d81d8e07ada": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007d349d8b7842658f5f15377e3a501f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020e39d530554e3cb41e5e4e6243c823": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae498964e94f42acb7c67395dfbe5edd",
            "max": 17518525,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fe161f53570417ba7efd357ca06e7dd",
            "value": 17518525
          }
        },
        "02db2565a2dd4260b60ae74340c32d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b5e30ccb8cd4eb4bb712bcefd6158af",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6e65b24b034d4eb0aaf0bced3a792fda",
            "value": "tokenizer.model:â€‡100%"
          }
        },
        "0314d24d16bf46918ea73d472573c7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0476063cc726418fa7be30d8e9d9db2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04801bcbee20430ca103b1c4a5e44a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb2c00a64dd14935a27df2030314667b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5b80944363af4b2da56bc0b0158d16de",
            "value": "â€‡4200/4200â€‡[00:00&lt;00:00,â€‡5016.41â€‡examples/s]"
          }
        },
        "04b3451b87cf4b038803b3f41ff1b0cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05668d441d7347c6aff6d4d34095b8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05a09f1ae0f2433ca932f643f2f4cc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0314d24d16bf46918ea73d472573c7dd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_80f2df7010a44bc994845dcda306d916",
            "value": "Map:â€‡100%"
          }
        },
        "08ca2f99eb37478c9383aada2b9c4e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2355800c4345568e90931a15f771db",
            "max": 1839649888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1550bc28bf84cb7bb9395c450cb63cb",
            "value": 1839649888
          }
        },
        "0a8942b119324312af97d4fd73b29b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c919c1b5db824b78bf23c1b233511d43",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_61635bfde06247608f86bf26308ee3b9",
            "value": "100%"
          }
        },
        "0b2597ff13eb47acbfe4a55a876e9a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e67f33412214c968d0579886bfdeae1",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aeba7d7c0574bbc8155fc337e12cb51",
            "value": 4241003
          }
        },
        "101b0ff2dbd84d53b69798291340a4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89db042077b5443e91c978587cc74b1e",
            "max": 2071334153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eea5debba9bf42c78247a4d6dc93bc03",
            "value": 2071333956
          }
        },
        "138ae713df654b9cb210c44645996b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef69f02928e4970a37c4e9eaeb29fdc",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbbe182cccd5405a9dc611642b6691f6",
            "value": 636
          }
        },
        "163dfc72f01848e895dc07c1bc6a832a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a2250aa60b43b3924b2c42e536409d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66f29807805d4deba2be97392bb23e9d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d7b97bee444347038f8e755f5fe2d39f",
            "value": "â€‡1/1â€‡[00:16&lt;00:00,â€‡16.62s/it]"
          }
        },
        "17f0ed3f984549189d96fda6c4fcb974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df6d1c5d8b624e65a1ba6fb370b4a3d1",
              "IPY_MODEL_d9063cfbec0d4b7180f13d9bd434f737",
              "IPY_MODEL_04801bcbee20430ca103b1c4a5e44a9e"
            ],
            "layout": "IPY_MODEL_79ed6acbe87e435f9a6f1c5494c45560"
          }
        },
        "2040287ef7164618a25ae004028d1fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c080b3f9484b49bf328b61fb7cc860": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "221a9b339aaa4c0da99c85851b88d1f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23233d21b94046419cb129a22fd4affd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e3e647f48349f985a1a6af3229623d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e055c0fdc5fc4666a0e48aa5f0bbcfda",
            "value": "unsloth.Q8_0.gguf:â€‡"
          }
        },
        "23bb83d49ba34934a78b4eb049bcea42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25dc782ccf8847d7936720bbca9baa12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c9c7fb62e944c6daad7d77555dd73fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61045119a1be499da497eca727457205",
              "IPY_MODEL_f8b30af0a46248a282d1fb4a215ff4fe",
              "IPY_MODEL_8758cf23949e457d879d16acc58e5f55"
            ],
            "layout": "IPY_MODEL_7fb069b7acd7497caf4c29068bcb6dbb"
          }
        },
        "2e2355800c4345568e90931a15f771db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d9126177b149758dcbdcf42809d881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87127a319f0b40e59918fb718edf28c5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4f1fc66450d442c984a137f2037b0df6",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "36dcf482487641dfbc0462372d5df200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_644a9739650b43d48ffbe950ece074f3",
              "IPY_MODEL_101b0ff2dbd84d53b69798291340a4d1",
              "IPY_MODEL_ee9a3d4ee2e34e319eda1b9b4d10c49e"
            ],
            "layout": "IPY_MODEL_ebff33d290c24bf78ba41c6195227b83"
          }
        },
        "3aad570f9bf24029b1c771e4c3ea3a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74609d62cc87424091aef609e0b8f365",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25dc782ccf8847d7936720bbca9baa12",
            "value": 1
          }
        },
        "3d24792983064082b3258f8d7561a714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acae8f5e411d4a3f8f723b342f928d65",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_abbfab7e68df4703a328c4b38997e784",
            "value": "unsloth.Q5_K_M.gguf:â€‡"
          }
        },
        "3fe161f53570417ba7efd357ca06e7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "496c0e9f5a404704a9920693b41e92e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ed9de6d9e8b444894c5ebd87aefcf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ca8fcc1faf406e8c809872552e6b7c",
            "max": 154,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05668d441d7347c6aff6d4d34095b8f5",
            "value": 154
          }
        },
        "4f1fc66450d442c984a137f2037b0df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5656a2f25079495692cac526edbd5f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58971006c2ca4d5e83357f8dc70c11f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0612875a1dc4c858d240bdb19d4c2a7",
              "IPY_MODEL_aef99fc38f17468289f3a1175a01d4fc",
              "IPY_MODEL_a1951547b51a486e8e574363d93ed12b"
            ],
            "layout": "IPY_MODEL_e0061933e2864df8b2b3f43a8e461258"
          }
        },
        "58aa77c2b6e54d38a40fd84dae016823": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5656a2f25079495692cac526edbd5f1e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bffc3facdc394fc6b1a8654279909597",
            "value": "â€‡636/636â€‡[00:00&lt;00:00,â€‡46.6kB/s]"
          }
        },
        "5a126cfba190437d821142251035ef75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b80944363af4b2da56bc0b0158d16de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bb8db0042b446d093d287e43232a7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e5ade2662904e7b8c581d2cdc4b906e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61045119a1be499da497eca727457205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbfbfcabe9fe4e5dad74c8798312552f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f45a55fe04ab48c390a83504b92d3830",
            "value": "100%"
          }
        },
        "610f6177cfd44b70850543685efcb185": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9dcec7f48774b96b235640d8ecffe80",
              "IPY_MODEL_138ae713df654b9cb210c44645996b3e",
              "IPY_MODEL_58aa77c2b6e54d38a40fd84dae016823"
            ],
            "layout": "IPY_MODEL_eaee053bf01745cbbcc885ba88f4e5e4"
          }
        },
        "61635bfde06247608f86bf26308ee3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6230dcdcd36a4e139c50aade200fb4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6376f6c22b6443eea076ea33a27e21b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644a9739650b43d48ffbe950ece074f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007d349d8b7842658f5f15377e3a501f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8880c2f330be497abfc214adaca8ede9",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "66f29807805d4deba2be97392bb23e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6878ce769cb2483d857fbe24100f6416": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a8aca09ef624e87855cd3320152cc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d45b8d9c9fb4fe9b31a91422aea05a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5bb8db0042b446d093d287e43232a7c6",
            "value": "â€‡154/154â€‡[00:00&lt;00:00,â€‡7.40kB/s]"
          }
        },
        "6cbd51600f4043dfb69bce2b7ff745b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8694beaedf4452ab736f6af84f21de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c656ded7ba114460ae7bdcfa1e09d09f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c0f72306b7ae4838886e3d3286ec2c23",
            "value": "â€‡4.24M/4.24Mâ€‡[00:00&lt;00:00,â€‡17.0MB/s]"
          }
        },
        "6e65b24b034d4eb0aaf0bced3a792fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e67f33412214c968d0579886bfdeae1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f7b3f094e7742b6a3ed35d36c528d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74609d62cc87424091aef609e0b8f365": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7991d1feed4742598e81147ab7a017c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ed6acbe87e435f9a6f1c5494c45560": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a34c57912ac4b6c817773c4804b544e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30d9126177b149758dcbdcf42809d881",
              "IPY_MODEL_a573b5c1c672440391a8fe61fa1fe8da",
              "IPY_MODEL_a28fd4c776494e5eb4eb85913e149e2b"
            ],
            "layout": "IPY_MODEL_2040287ef7164618a25ae004028d1fdc"
          }
        },
        "7aeba7d7c0574bbc8155fc337e12cb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cb901bce8664f8dabaeacc52d3bb1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cf95ec94ded417a8bc4ba0ecc751be5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d45b8d9c9fb4fe9b31a91422aea05a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb069b7acd7497caf4c29068bcb6dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f2df7010a44bc994845dcda306d916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "813acd4406a647f99bdabdd3a99ae8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76f57c399cc48338fb95cacea292f93",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7098cbb996a4fe5905bd0a3b500073e",
            "value": 1
          }
        },
        "8623c2835aee46d08eead7c2b025ebfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87127a319f0b40e59918fb718edf28c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8758cf23949e457d879d16acc58e5f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe92c00f2ed6449da1af94a30514b71f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d4805764b6fc4fbd9949b4ca4fe9c451",
            "value": "â€‡1/1â€‡[00:15&lt;00:00,â€‡15.80s/it]"
          }
        },
        "882985a6a26544c1bb63b52c9f7e7241": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8880c2f330be497abfc214adaca8ede9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89db042077b5443e91c978587cc74b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a531745d9d2474ca3ddc73cb274bc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b8295182e8049e29b0431a314ea4bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e6a1e0e3c324018bc83dd12942865a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eb9cd54b4dc4692b24b6452fb63de86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fdad3bfd3a942a48a17b5ed34370325": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b45001e9f148dc8fc507a19c380c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ca8fcc1faf406e8c809872552e6b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9869435e408640e1a8ead714ac110c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b5e30ccb8cd4eb4bb712bcefd6158af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3d354965da4c36a88fc7f4578bdb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0612875a1dc4c858d240bdb19d4c2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f524c709a6814c5f845b206964a38588",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d7d1c64a0d7f44d9bc4f31b9c92ca5cd",
            "value": "unsloth.Q4_K_M.gguf:â€‡"
          }
        },
        "a1951547b51a486e8e574363d93ed12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5ade2662904e7b8c581d2cdc4b906e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee74f515bb9f418eb0dfd3448c01b95e",
            "value": "â€‡1.63G/?â€‡[00:15&lt;00:00,â€‡919MB/s]"
          }
        },
        "a1a881e7f2954be7a38e613d2ee32601": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02db2565a2dd4260b60ae74340c32d65",
              "IPY_MODEL_0b2597ff13eb47acbfe4a55a876e9a34",
              "IPY_MODEL_6d8694beaedf4452ab736f6af84f21de"
            ],
            "layout": "IPY_MODEL_6cbd51600f4043dfb69bce2b7ff745b1"
          }
        },
        "a1f92659fb70428db331302af3441000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bb4bea7c774b54a45e0cd6f3278f62",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e62100e7f631432884539a2020787bc3",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "a28fd4c776494e5eb4eb85913e149e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff86d22020714911a19c0bce7c965b25",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fc0ac78985ac4a978fb1cd639264faa4",
            "value": "â€‡40.6k/40.6kâ€‡[00:00&lt;00:00,â€‡1.72MB/s]"
          }
        },
        "a4eb53e328c441088ea2a9a6c8a9d8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a8942b119324312af97d4fd73b29b93",
              "IPY_MODEL_813acd4406a647f99bdabdd3a99ae8f7",
              "IPY_MODEL_f9310d3691a645778a74bb12ace3a55b"
            ],
            "layout": "IPY_MODEL_04b3451b87cf4b038803b3f41ff1b0cd"
          }
        },
        "a56795ce4f5a4204b165b3fa468a202c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a573b5c1c672440391a8fe61fa1fe8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d227b74b2ec84a0ca966debd72860608",
            "max": 40634,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6230dcdcd36a4e139c50aade200fb4b8",
            "value": 40634
          }
        },
        "a611a94cda3b4f9a97bfc496e618bf9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abbfab7e68df4703a328c4b38997e784": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac25224af7284b1abe2e7e19f0de393c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a126cfba190437d821142251035ef75",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_90b45001e9f148dc8fc507a19c380c39",
            "value": "100%"
          }
        },
        "acae8f5e411d4a3f8f723b342f928d65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae498964e94f42acb7c67395dfbe5edd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef99fc38f17468289f3a1175a01d4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb90d2e5869c4162979674adc57a068b",
            "max": 1630262368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a611a94cda3b4f9a97bfc496e618bf9b",
            "value": 1630262368
          }
        },
        "b10b5137b3294d51a89de1e494aa156e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221a9b339aaa4c0da99c85851b88d1f2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0476063cc726418fa7be30d8e9d9db2e",
            "value": "â€‡2.67G/?â€‡[00:23&lt;00:00,â€‡504MB/s]"
          }
        },
        "b10d9bc070254af1a9b381e790952cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b351df09444e7e924da1586cebe2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7bc6c978ccb4991901b31a580111bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6878ce769cb2483d857fbe24100f6416",
            "max": 4200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a531745d9d2474ca3ddc73cb274bc0d",
            "value": 4200
          }
        },
        "bb67d619a0304d47925fb8bc7a9c39bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac25224af7284b1abe2e7e19f0de393c",
              "IPY_MODEL_3aad570f9bf24029b1c771e4c3ea3a61",
              "IPY_MODEL_17a2250aa60b43b3924b2c42e536409d"
            ],
            "layout": "IPY_MODEL_163dfc72f01848e895dc07c1bc6a832a"
          }
        },
        "bb90d2e5869c4162979674adc57a068b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bffc3facdc394fc6b1a8654279909597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c04f45cb9ce24d42827e126a8767a17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3bf3bafaa234315b3313e4de4c5f192",
            "max": 2669069408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b8295182e8049e29b0431a314ea4bdc",
            "value": 2669069408
          }
        },
        "c09acd7299734d369c9bd1136a13cb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0f72306b7ae4838886e3d3286ec2c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c482ffad2ca34238aa2650b31a794c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c656ded7ba114460ae7bdcfa1e09d09f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6bfb0916d244358a59ac2bc7d9adc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c482ffad2ca34238aa2650b31a794c1c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6f7b3f094e7742b6a3ed35d36c528d70",
            "value": "â€‡1.84G/?â€‡[00:16&lt;00:00,â€‡1.48GB/s]"
          }
        },
        "c919c1b5db824b78bf23c1b233511d43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9dcec7f48774b96b235640d8ecffe80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882985a6a26544c1bb63b52c9f7e7241",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c09acd7299734d369c9bd1136a13cb1d",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "cbbe182cccd5405a9dc611642b6691f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce694697bbe947fa89a3cadeaabb2d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d227b74b2ec84a0ca966debd72860608": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4805764b6fc4fbd9949b4ca4fe9c451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4982b2c04a04c5d92b0a6bcfc7ff267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05a09f1ae0f2433ca932f643f2f4cc49",
              "IPY_MODEL_b7bc6c978ccb4991901b31a580111bf7",
              "IPY_MODEL_fe5b7f91f3fa484da54c12faf6d51ae1"
            ],
            "layout": "IPY_MODEL_b4b351df09444e7e924da1586cebe2a6"
          }
        },
        "d679d7942f4448ea8e32941acd39a152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d76f57c399cc48338fb95cacea292f93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b97bee444347038f8e755f5fe2d39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d1c64a0d7f44d9bc4f31b9c92ca5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9063cfbec0d4b7180f13d9bd434f737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bb83d49ba34934a78b4eb049bcea42",
            "max": 4200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea14f712e6d245899503692207100265",
            "value": 4200
          }
        },
        "da27e391ff0346d682fe26e45d0433e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5bf26f820394df2879d72bfd046c883",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ce694697bbe947fa89a3cadeaabb2d37",
            "value": "â€‡17.5M/17.5Mâ€‡[00:00&lt;00:00,â€‡41.9MB/s]"
          }
        },
        "dbfbfcabe9fe4e5dad74c8798312552f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5d9f2f667f4df7a1d58713ced72164": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b10d9bc070254af1a9b381e790952cd6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9d3d354965da4c36a88fc7f4578bdb88",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "df17d60cc7374c1488d2d33460326c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23233d21b94046419cb129a22fd4affd",
              "IPY_MODEL_c04f45cb9ce24d42827e126a8767a17f",
              "IPY_MODEL_b10b5137b3294d51a89de1e494aa156e"
            ],
            "layout": "IPY_MODEL_496c0e9f5a404704a9920693b41e92e8"
          }
        },
        "df3e1d0be28c405e85d2379f02991226": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d24792983064082b3258f8d7561a714",
              "IPY_MODEL_08ca2f99eb37478c9383aada2b9c4e31",
              "IPY_MODEL_c6bfb0916d244358a59ac2bc7d9adc19"
            ],
            "layout": "IPY_MODEL_a56795ce4f5a4204b165b3fa468a202c"
          }
        },
        "df6d1c5d8b624e65a1ba6fb370b4a3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cf95ec94ded417a8bc4ba0ecc751be5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8eb9cd54b4dc4692b24b6452fb63de86",
            "value": "Map:â€‡100%"
          }
        },
        "e0061933e2864df8b2b3f43a8e461258": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e055c0fdc5fc4666a0e48aa5f0bbcfda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0bb4bea7c774b54a45e0cd6f3278f62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1550bc28bf84cb7bb9395c450cb63cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3bf3bafaa234315b3313e4de4c5f192": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62100e7f631432884539a2020787bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7098cbb996a4fe5905bd0a3b500073e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea14f712e6d245899503692207100265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaee053bf01745cbbcc885ba88f4e5e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2c00a64dd14935a27df2030314667b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebff33d290c24bf78ba41c6195227b83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee74f515bb9f418eb0dfd3448c01b95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee9a3d4ee2e34e319eda1b9b4d10c49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00700277731a4f64b1c99d81d8e07ada",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8623c2835aee46d08eead7c2b025ebfc",
            "value": "â€‡2.07G/2.07Gâ€‡[00:16&lt;00:00,â€‡491MB/s]"
          }
        },
        "eea5debba9bf42c78247a4d6dc93bc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eef69f02928e4970a37c4e9eaeb29fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f212ca7310904947918097a71f40d0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1f92659fb70428db331302af3441000",
              "IPY_MODEL_020e39d530554e3cb41e5e4e6243c823",
              "IPY_MODEL_da27e391ff0346d682fe26e45d0433e3"
            ],
            "layout": "IPY_MODEL_7991d1feed4742598e81147ab7a017c6"
          }
        },
        "f3e3e647f48349f985a1a6af3229623d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45a55fe04ab48c390a83504b92d3830": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f524c709a6814c5f845b206964a38588": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5bf26f820394df2879d72bfd046c883": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b30af0a46248a282d1fb4a215ff4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c080b3f9484b49bf328b61fb7cc860",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cb901bce8664f8dabaeacc52d3bb1c3",
            "value": 1
          }
        },
        "f9310d3691a645778a74bb12ace3a55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fdad3bfd3a942a48a17b5ed34370325",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d679d7942f4448ea8e32941acd39a152",
            "value": "â€‡1/1â€‡[00:23&lt;00:00,â€‡23.84s/it]"
          }
        },
        "f9c1f77c2cd64807a9465386548765bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd5d9f2f667f4df7a1d58713ced72164",
              "IPY_MODEL_4ed9de6d9e8b444894c5ebd87aefcf54",
              "IPY_MODEL_6a8aca09ef624e87855cd3320152cc62"
            ],
            "layout": "IPY_MODEL_9869435e408640e1a8ead714ac110c2c"
          }
        },
        "fc0ac78985ac4a978fb1cd639264faa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe5b7f91f3fa484da54c12faf6d51ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6376f6c22b6443eea076ea33a27e21b1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8e6a1e0e3c324018bc83dd12942865a7",
            "value": "â€‡4200/4200â€‡[00:15&lt;00:00,â€‡155.89â€‡examples/s]"
          }
        },
        "fe92c00f2ed6449da1af94a30514b71f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff86d22020714911a19c0bce7c965b25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
